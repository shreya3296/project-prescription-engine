# -*- coding: utf-8 -*-
"""embeddings_bioBERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14bWJUdDWqtDNTeprK-OK3EX9TqSo1kk6

## Code to run the embeddings and merge diagnosis and ICD-10 codes
"""

import pandas as pd
import re
from sklearn.metrics.pairwise import cosine_similarity
import os
if 'TRANSFORMERS_CACHE' not in os.environ:
    # defaults to /nonexistent if unset
    os.environ['TRANSFORMERS_CACHE'] = '/tmp'
from transformers import BertTokenizer, BertModel
import numpy as np
import sys

# Open files, load the data sets already pre-processed and the ICD-10 data base
icd10 = pd.read_csv(sys.argv[1], header=None, names=['code', 'description'])

# Take input params for (1) input file path and (2) output file paths
db1 = pd.read_json(sys.argv[2], lines=True)
db2 = pd.read_json(sys.argv[3], lines=True)
embeddings_output_path = str(sys.argv[4])

# function to remove upper cases and strange symbols
def preprocess_text(text):
    # Convert to lowercase
    text = text.lower()
    # Remove special characters (keeping spaces)
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    return text

# apply preprocessing to the diagnosis that will be embedded
icd10['description'] = icd10['description'].apply(preprocess_text)

# load tokenizer and model for bioBERT
tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1')
model = BertModel.from_pretrained('dmis-lab/biobert-v1.1')

# function to create the embeddings of the diagnosis and descriptions
def text_to_embedding(text):
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)
    outputs = model(**inputs)
    embedding = outputs.last_hidden_state.mean(dim=1).detach().numpy()
    assert isinstance(embedding, np.ndarray)
    return embedding

# merge the two initial data sets
merged_db = pd.concat([db1, db2])

# get embeddings
db1_embeddings = db1['diagnosis'].apply(text_to_embedding)
db2_embeddings = db2['diagnosis'].apply(text_to_embedding)
icd10_embeddings = icd10['description'].apply(text_to_embedding)

# create and embeddings column for future use in the dashboard
icd10['diagnosis_embedding'] = icd10_embeddings

icd10_embeddings_array = np.vstack(icd10_embeddings.apply(lambda x: x.reshape(1, -1)).to_numpy())

# match ICD-10 codes using cosine similarity
# important! the embeddings must be a numpy array, otherwise it will not work
def match_icd10(diagnosis_embedding):
    similarities = cosine_similarity(diagnosis_embedding.reshape(1, -1), icd10_embeddings_array)[0]
    best_match_index = similarities.argmax()
    return icd10['code'][best_match_index]

merged_db['diagnosis_embedding'] = pd.concat([db1_embeddings, db2_embeddings])

merged_db['icd10_code'] = merged_db['diagnosis_embedding'].apply(match_icd10)

merged_db.drop(columns=['diagnosis_embedding'], inplace=True)

merged_db = pd.merge(merged_db, icd10[['code', 'description']], left_on='icd10_code', right_on='code', how='left')
merged_db.drop(columns=['code'], inplace=True)

merged_db['icd10_code'].to_json(embeddings_output_path)